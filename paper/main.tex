\documentclass[english]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{comment}
\usepackage{svg}
\usepackage{caption, booktabs}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{fancyhdr}
% \usepackage[disable]{todonotes}
\usepackage{todonotes}
\usepackage{units}
\usepackage[left=2cm,right=4cm,top=2cm,bottom=2cm]{geometry}
\usepackage[
colorlinks=true,
	citecolor=black,
  urlcolor=black,
	linkcolor=black
]{hyperref}
\newcommand{\scidatalogo}{\includegraphics[height=36pt]{SciData_logo.jpg}}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\setlength{\headheight}{40pt}
\lhead{\textsc{\scidatalogo}}
\usepackage{natbib}

% \usepackage{helvet}

% \renewcommand{\familydefault}{\sfdefault}

\begin{document}
\input{descr-stats-ao-events.tex}
\input{descr-stats-av-events.tex}
\input{descr-stats-anno.tex}

% title has to be < 110 chars incl. spaces at the moment 106 Chars
\title{Processing of visual and non-visual naturalistic spatial information in
  the "parahippocampal place area"}

\author{
    Christian~O.~Häusler\textsuperscript{1,2{*}},
    Simon B. Eickhoff\textsuperscript{1,2},
    Michael Hanke\textsuperscript{1,2}}
% https://www.nature.com/sdata/publish/for-authors#other-formats

\maketitle
\thispagestyle{fancy}

1. Psychoinformatics Lab, Institute of Neuroscience and Medicine, Brain \&
Behaviour (INM-7), Research Centre Jülich, Jülich, Germany, 2. Institute of
Systems Neuroscience, Medical Faculty, Heinrich Heine University,  Düsseldorf,
Germany {*}corresponding author: Christian Olaf Häusler (der.haeusler@gmx.net)


\begin{abstract}
% < 170 words new analysis of existing data of interest to a broad section of
% our audience highlighting innovative examples of data reuse may be used to
% present compelling new findings & conclusions derived from published.
Neuroimaging studies have parcellated the human brain into distinct functional
areas.
% PPA
A region in the human hippocampal cortex termed ``parahippocampal place area''
is classically considered to be a higher visual area as increased hemodynamic
activity in the PPA correlates with the perception of static pictures of
landscapes compared to pictures of faces or objects.
% AV, AD: operationalization
In this study, we explore different ways to operationalize the perception of
spatial information in 14 subjects that were watching an audio-visual Hollywood
movie and listened to the movie's audio-description (studyforrest.org).
% auditory localizer?
Focussing on the audio-description, we test if an auditory narrative could
localize a ``visual area'' in individual subjects.
% GLM
For each naturalistic stimulus, we model hemodynamic activity via several
general linear model (GLM) $t$-contrasts that are based on annotations of
selected stimulus features.
% VIS
Current results are compared to results of classic visual localizer experiment
that we conducted previously to localize the PPA in the same participants.
% no refs in abstract (probably)
%\citep{sengupata2016extension}.  results: group AV
On a group level, results for a visual movie stimulus show significantly
increased hemodynamic activity spatially overlapping with a traditionally
localized PPA but also extending into earlier visual cortices.
% results: group AD
Results for the audio-description stimulus reveal significant activation
restricted to the anterior part of the PPA.
% results: individual AD
On an individual level, results of the audio-description show significant
bilateral clusters in the anterior PPA of nine subjects and significant
unilateral clusters in two subjects.
% conclusion: generalizability
Results suggest that increased activation in the PPA during the perception of
static pictures generalizes to the perception of spatial information embedded in
an audio-visual movie and an exclusively auditory stimulus.
% conclusion: PPA has subregions
Our results provide further evidence that the PPA can be divided into functional
subregions.
% localizer substitute
[An auditory narrative might substitute a visual paradigm to localize the PPAs
anterior part in visually impaired subjects.]
\end{abstract}

\section*{Keywords}
% maximal 8
fMRI, naturalistic stimulus, spatial perception, vision, language, speech,
narrative, studyforrest

\pagebreak[4]

\section*{Plan}


\noindent Generally

\begin{itemize}
    \item [text in brackets] can probably be deleted
    \item imo AD and AV can be written as movie and audio-description
\end{itemize}


\noindent Method:

\begin{itemize}
    \item Fig regressor correlations: maybe write out in full the name of
        regressors (instead of pointing to the table)
    \item different frame counts of segments AV vs. AD
\end{itemize}


\noindent Results

\begin{itemize}
    \item tables: round p-values to ?
\end{itemize}

\noindent Discussion
\begin{itemize}
    \item "Lokalisation der PPA" vs. "Antwortverhalten einer vorab definierten
        PPA". Machst wohl das erste, beschreibst es aber als das zweite
    \item Summary / Concluding statement
        (data reuse to present compelling new findings \& conclusions derived
        from published.)
\end{itemize}


\noindent Supplemental Material
\begin{itemize}
    \item restructure (results + discussion AV, then AD)
    \item discuss differences of contrasts (s. Simons comment)
\end{itemize}


\noindent Code Availability
\begin{itemize}
    \item https://www.springernature.com/gp/authors/research-data-policy/data-availability-statements/12330880i
\end{itemize}


\noindent Data Availability
\begin{itemize}
    \item s. other psyinfo paper
\end{itemize}

\pagebreak[4]


\section{Introduction}

% Limit for main text (intro, results and discussion) = ca. 3k words

% brain mapping via fMRI
Humans can perceive and make sense of their daily environment casually and
seemingly without any effort.
%
Studies in the field of neuropsychology and neuroimaging (e.g.
\citep{penfield1950cerebral, fox1984noninvasive}) have shown that different
parts of the brain are specialized for different perceptual and cognitive
functions.
% occipital cortex for vision -> two pathways
The occipital cortex is considered to be primarily involved in the early stages
of visual perception and giving rise to two distinct pathways that process
different kind of visual information:
% dorsal vs ventral pathway
a dorsal stream (the ``where pathway'') that leads into the parietal lobe, and a
ventral stream (the ``what pathway'') that leads into into the temporal lobe
\citep{goodale1992separate, mishkin1982contribution}.
% PPA
A classic example of a higher-level visual area in the ventral pathway is the
``parahippocampal place area'' (PPA) \citep{epstein1998ppa,
epstein1999parahippocampal}.
% anatomical location != functional location
The PPA is located in the posterior parahippocampal gyrus including adjacent
regions of the fusiform gyrus and anterior lingual gyrus
\citep{epstein2008parahippocampal}.
% neural correlate of scene perception
Increased hemodynamic activity is observed in the PPA when subjects view
pictures of landscapes, buildings or landmarks (compared to e.g. pictures of
faces or tools) during blood oxygenation level-dependent functional magnetic
resonance imaging (BOLD fMRI) \citep{aguirre1998area, epstein2014neural,
epstein1998ppa, troiani2012object}.

% literature review overview 1: imagination & haptic exploration
Increased hemodynamic activity in the PPA generalizes to mental imagination of
landscapes \citep{ocraven2000mental} and haptic exploration of scenes
constructed from LEGO blocks \citep{wolbers2011modality}.
% O'Craven: watching pictures
In a study conducted by \cite{ocraven2000mental} participants viewed alternating
blocks of pictures showing familiar places and famous faces during an initial
experimental paradigm.
% O'Craven: mental imagery
In a subsequent paradigm, participants were instructed to ``form a vivid mental
image'' of the previously viewed pictures.
% O'Craven results
The PPA showed increased activation during imagination of places compared to
faces but the imagination tasks showed a smaller activation level compared to
the perceptual task.
% Wolbers: haptic exploration
In a block design study conducted by \cite{wolbers2011modality} the PPA of
[sighted] participants showed increased activation during a delayed
match-to-sample task of haptically explored scenes constructed from LEGO bricks
compared to abstract geometric objects.
% Wolbers: connectivity analysis

% Aziz (2008): place related sentences
To our knowledge only one study \citep{aziz2008modulation} compared hemodynamic
activity levels in the PPA that were correlated with different semantic
categories occurring in spoken language.
% Aziz' stimuli; ``The Taj Mahal faces a long thin reflecting pool'', ``Marilyn
% Monroe has a large square jaw'', ``The television has a long antenna''
\cite{aziz2008modulation} used sentences that described famous or generic places
and faces, or objects.
% Aziz' tasks:
Participants were instructed to press a button whenever the sentence described
an inaccurate or improbable fact (e.g. ``Marilyn Monroe has a large square
jaw'').
% Aziz' results:
Activation in the left, but not right, PPA was significantly reduced when
participants listened to place-related sentences compared to listening to
face-related sentences. Moreover, this effect was only observed in sentences
involving famous places.

% summary if literature review
In summary, studies suggest that the PPA does preferably but not exclusively
respond to visually presented spatial information.
% three things in common
All reviewed studies share three common aspects:
% designed stimulus set
First, they employed a small sets of carefully chosen and conceptualized
stimuli.
% block-design & task
Second, studies used block-design paradigms to maximize detection power.
Further, they usually employed an explicit (perceptual) judgement task.
% conceptualized stimuli and block: disadvantages
Block-design studies that use conceptualized stimuli and a task have the
advantage of controlling confounding variables (e.g. color, luminance, size,
spatial frequencies, sentence length), maximizing detection power, and keeping
participants paying attention to the stimuli.
% conceptualized stimuli and block: disadvantages
Nevertheless, small sets of conceptualized stimuli and block-design paradigms
lack external and ecological validity \citep{westfall2016fixing,
hasson2004intersubject} because they poorly resemble how we, free of a[n
explicit] perceptual task, experience our rich/multidimensional and continuous
environment that our brains are accommodated to
\citep{sonkusare2019naturalistic}.
% Moreover, study participants can and will become aware about which perceptual
% process is examined in the study by merely being exposed to the experimental
% paradigm.
Third, the reviewed studies averaged results across 7-11 subjects.
% averaging pros and cons
The averaging approach improves signal-to-noise ratio (SNR) but does not
characterize brain functions at an individual level, a prerequisite for the
application of brain imaging methods in individual diagnostics (cf.
\cite{dubois2016building, eickhoff2020towards}).

% open question
In this study, we investigate if increased hemodynamic activity in the PPA that
is usually revealed by contrasting blocks of pictures can also be revealed under
more ecologically conditions.
% we use 2 naturalistic stimuli
To answer this question, we operationalized the perception of both visual and
auditory spatial information using two naturalistic stimuli (see
\citep{hamilton2018revolution, hasson2008neurocinematics,
sonkusare2019naturalistic} for reviews).
% AV stimulus
The operationalization of visual perception is based on an annotation of cuts
and depicted locations in the audio-visual movie ``Forrest Gump'' (AV stimulus).
% AO stimulus
The operationalization of auditory perception is based on an annotation of
speech occurring in the movie's audio-description (AD stimulus).
% GLM contrasts
We then created several general linear model (GLM) contrast to analyze the
corresponding publicly available fMRI datasets of each naturalistic stimulus
\citep{hanke2016simultaneous, hanke2014audiomovie}
(\href{http://www.studyforrest.org}{studyforrest.org}).

% hypo a
We hypothesized that whole-brain analyses would reveal increased hemodynamic
activity spatially constrained to the PPA as functionally defined by a
traditional visual localizer experiment done with the same subjects
\citep{sengupta2016extension}.
% hypo b: individuals
Further, we hypothesized that an exclusively auditory stimulus could localize a
``visual area'' in individual subjects.
% application in individuals
An auditory stimulus substituting a visual experiment would be more practicable
to asses brain functions in visually impaired persons.
% results: group
On a group average level,
% operationalization in naturalistic stimuli
results demonstrate that our approach to operationalize spatial perception
during two naturalistic stimuli lead to increased hemodynamic activity in the
PPA.
% anterior vs. posterior
On both a group and individual subject level, the comparison of results from the
three datasets also suggests functional differences between the anterior and
posterior PPA.
% what does it mean
The current data add evidence to the hypothesis that the PPA might consist of
submodules that work together during visual perception of landscapes (cf.
\citep{baldassano2013differential}).
%
Lastly, our results suggest that the PPA's anterior part can be localized in
individual subjects by contrasting high-level semantic information occurring in
an auditory naturalistic stimulus.


\section{Methods}

% Specific data outputs should be explicitly referenced via data
% citation (see Data Records and Data Citations, below)}

% intro
We used three components of the publicly available
\href{http://www.studyforrest.org}{studyforrest.org} dataset that has already
been used by other research groups in independent studies (e.g.
\citep{ben2018hippocampal, jiahui2019predicting, hu2017decoding,
lettieri2019emotionotopy, nguyen2016integration}).
% used studies
The same subjects were
% AD
a) listening to the audio-description \citep{hanke2014audiomovie} of
the movie ``Forrest Gump'',
% AV
b) watching the audio-visual movie \citep{hanke2016simultaneous}, and
% VIS
c) participating in a dedicated six-category block-design visual localizer (VIS; \citep{sengupta2016extension}).
% see corresponding papers for details
An exhaustive description of the participants, stimulus creation, procedure,
stimulation setup, and fMRI acquisition can be found in the corresponding
publications. Following is a summary of the most important aspects.


\subsection{Participants}
% AD study
In the AD study \citep{hanke2014audiomovie}, 20 German native speakers (all
right-handed, age 21–38 years, mean age 26.6 years, 12 male) listened to the
German audio-description \citep{ForrestGumpGermanAD} of the movie ``Forrest
Gump'' \citep{ForrestGumpMovie}.
% AV study
In the AV study \citep{hanke2016simultaneous}, 15 participants (21–39 years,
mean age 29.4, six female) of the prior AD study watched the audio-visual movie
with dubbed German audio track \citep{ForrestGumpDVD}.
% VIS study
In the VIS study \citep{sengupta2016extension}, the same 15 participants took
part in a six-category block-design visual localizer.

% participants' health
All participants reported to have normal hearing, normal or corrected-to-normal
vision, and no known history of neurological disorders.
% compensation, consent and shit
In all studies, participants received monetary compensation and gave written
informed consent for their participation and for public sharing of obtained data
in anonymized form. The studies had prior approval by the Ethics Committee of
Otto-von-Guericke University of Magdeburg, Germany.


\subsection{Stimuli and Procedure}

% AD & AV stimulus name & references
We used the German DVD release \citep{ForrestGumpDVD} of the movie ``Forrest
Gump'' \citep{ForrestGumpMovie} and its audio-description that was broadcast as
an additional audio track for visually impaired listeners on Swiss public
television \citep{ForrestGumpGermanAD}.
% AV: voice-over
The plot of the movie is already carried by a voice-over of the main character
Forrest Gump.
% AD: additional narrator
In the largely identical audio-description, an additional male narrator
describes essential aspects of the visual scenery when there is no off-screen
voice, dialog, or other relevant auditory content.

% AD & AV: stimulus creation
The audio-description was temporally aligned to the audio track of the German
DVD release. A few scenes, less relevant to the main plot, were removed to create
the ``research cut'' lasting \unit[$\approx$2]{h} \citep{hanke2014audiomovie,
hanke2016simultaneous}.
% further processing
Both stimuli were further processed (filtering, volume adjustments) to improve
audibility during MRI scanning.
% splitting
Each stimulus was split into eight segments of approximately \unit[15]{minutes}.
% AD & AV: instructions
Before the experiment, participants were instructed to inhibit physical
movements except for eye-movements, and otherwise to simply ``enjoy'' the
stimulus.
% AD & AV: presentation & instructions
Audio-description and movie segments were presented in chronological order with
four segments in two fMRI sessions. Between sessions, participants left the
scanner for a break with a flexible duration. Structural images were obtained
during the first study on a day different from the fMRI session.

% VIS study picture categories
All stimuli of the VIS study were already used in a previous study
\citep{haxby2011common}.
%
There were 24 unique grayscale images (s. Figure 2 in
\citep{sengupta2016extension}) for each of six stimulus categories:
% category details
faces (cropped from original background presented on a medium-gray background),
bodies (female and male without heads in clothes; medium-gray background),
objects (e.g. binoculars, screw, chair, mug; medium-gray background), houses
(medium-gray background) and outdoor scenes comprising of nature and street
scenes, and phase scrambled images.
% controlled luminance and size
Images were matched in luminance and size of 400$\times$\unit[400]{px}.
% procedure: presentation & instructions
During the experiment, subjects were presented with four block-design runs, with
two \unit[16]{s} blocks per stimulus category in each run.
% temporal progression
Each image was shown for \unit[900]{ms} and images were separated by a fixation
cross lasting \unit[100]{ms}.
% task
Subjects also performed a one-back matching task to keep them attentive.


\subsection{Stimulation setup}

% AD
In the AD study, visual instructions were presented on a rear-projection screen
inside scanner bore. During the
functional scans, the projector presented a medium gray screen with the primary
purpose to illuminate a participant's visual field in order to prevent premature
fatigue.
% AV & VIS
In the AV and VIS study, visual instructions and stimuli were presented on a
rear-projection screen
% screen size \unit[23.75 $\times$ 10.25]{cm}
at a viewing distance of \unit[63]{cm}, with a movie frame projection size
approximately \unit[21.3]$^{\circ}$ $\times$ \unit[9.3]$^{\circ}$.
% angle of view: VIS
In the VIS study, stimulus images were displayed at a size of approximately
\unit[10]$^{\circ}$ $\times$ \unit[10]$^{\circ}$ of visual angle.
% AD & AV: auditory stimulation
Auditory stimulation was implemented using custom in-ear (AD), or over-the-ear
headphones (AV), which reduced the scanner noise by
at least \unit[20–30]{dB}.


\subsection{fMRI data acquisition}

Gradient-echo fMRI data for the AD study were acquired using a \unit[7]{Tesla}
Siemens MAGNETOM magnetic resonance scanner equipped with a 32 channel brain
receive coil at \unit[2]{s} repetition time (TR) with 36 axial slices (thickness
\unit[1.4]{mm}, \unit[1.4 $\times$ 1.4]{mm} in-plane resolution, \unit[224]{mm}
field-of-view, anterior-to-posterior phase encoding direction) and a
\unit[10]{\%} inter-slice gap, recorded in ascending order.
% slice orientation
Slices were oriented to include the ventral portions of frontal and occipital
cortex while minimizing intersection with the eyeballs.
% FOV
The field of view was centered on the approximate location of Heschl's gyrus.
% motion correction
EPI images were online-corrected for motion and geometric distortions.

% AV & VIS
In the AV and VIS study, a \unit[3]{Tesla} Philips Achieva dStream
MRI scanner with a 32 channel head coil acquired gradient-echo fMRI data
at \unit[2]{s} repetition time with
% slices
35 axial slices (thickness \unit[3.0]{mm}, \unit[10]{\%} inter-slice gap) with
\unit[80 $\times$ 80]{voxels} (\unit[3.0 $\times$ 3.0]{mm} of in-plane
resolution, \unit[240]{mm} field-of-view) and an anterior-to-posterior phase
encoding direction, recorded in ascending order.
% no. of volumes
A total of 3599 volumes were recorded for each participant in each of the
naturalistic stimulus paradigms (AD and AV).

\subsection{Preprocessing}

% data sources
% https://github.com/psychoinformatics-de/studyforrest-data-aligned/tree/master/code
% https://github.com/psychoinformatics-de/studyforrest-data-templatetransforms}
All analyses presented here are based on previously published fMRI data
(\url{https://github.com/psychoinformatics-de/studyforrest-data-aligned}).
Of those 15 participants in the studyforrest dataset that took
part in all three experiments,
% exclusion of VP 10
data of one participant were dropped to due to invalid distortion correction
during scanning of the AD stimulus.
Data were previously corrected for motion, aligned with and re-sliced onto a
participant-specific BOLD template image \citep{sengupta2016extension}
(uniform spatial resolution of \unit[2.5$\times$2.5$\times$2.5]{mm} for both
AD and AV data).
% preprocessing intro
All analyses presented here were carried out using
FSL v5.0.9 (\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software Library};
\citep{smith2004fsl}) on a computer cluster running the Debian GNU/Linux
operating system. Software packages were obtained from repositories of
\href{http://neuro.debian.net}{NeuroDebian} \citep{halchenko2012open}.

% my preprocessing
Preprocessing was performed by FEAT v6.00 (FMRI Expert Analysis Tool;
\citep{woolrich2001autocorr}) as shipped with FSL.
% temporal filtering
High-pass temporal filtering was applied to every stimulus segment using a
Gaussian-weighted least-squares straight line with a cutoff period of
\unit[150]{s} (sigma=\unit[75.0]{s}) to remove low-frequency confounds.
% brain extraction
The brain was extracted from surrounding tissues using BET \citep{smith2002bet}.
% spatial smoothing
Data were spatially smoothed applying a Gaussian kernel with full width at half
maximum (FWHM) of \unit[4.0]{mm}.
% normalization
A grand-mean intensity normalization of the entire 4D dataset was performed by a
single multiplicative factor.
% pre-whithening
Correction for local autocorrelation in the time series (prewhitening) was
applied using FILM (FMRIB's Improved Linear Model; \citep{woolrich2001autocorr})
to improve estimation efficiency.


\subsection{Event selection} \label{rationale}

% traditionally
Traditionally, researchers design stimuli that presumably would trigger the
perceptual process of interest while also controlling confounding variables
(e.g. color, luminance).
% our approach: annotation and regressors
Naturalistic stimuli mimic how we experience the world more closely but have the
drawback that they are usually fix and that their temporal structure is unknown.
% annotation ftw
Hence, we annotated the temporal structure of various stimulus features that
later served as basis [for GLM regressors] to model hemodynamic responses.

% AV anno
For the analysis of the AV stimulus, we took advantage of a previously published
annotation of [the 869] movie cuts and the depicted location after each cut
\citep{haeusler2016cutanno}.
% rationale to use that annotation rationale behind using movie cuts
Our rationale was that cuts are ``spatially relevant'' events that re-orient the
viewer within the environment of the movie by either switching to another
setting or switching the perspective within the same setting.
% AV regressors/events
Each cut was put into one of the following five categories (see Table
\ref{tab:av-events}):
%
1) a cut switching to a setting that was depicted for the first time
(\texttt{vse\_new}),
%
2) a cut switching to a setting that was already depicted earlier in the movie
(\texttt{vse\_old}),
%
3) a cut switching to another locale within a setting (\texttt{vlo\_ch}; e.g. a
cut from first to the second floor in Forrest's house),
%
4) a cut to another camera position within a setting or locale that was depicted
for the first time (\texttt{vpe\_new}), and
%
5) a cut to another camera position within a setting or locale that was already
depicted before (\texttt{vpe\_old}).

% irrespective of visual content
Notably, categorization was performed irrespectively of a movie frame's precise
content and thus without controlling confounding variables.
% assumption
We assumed that different categories would - on average - depict different
stimulus features.
% cinematographic rationale cut to new scenes: establishing shots
The cinematographic rationale was that movie shots tend to establish the setting
(\texttt{vse\_new}) and the spatial layout within a setting (\texttt{vpe\_new})
at the beginning of a movie.
% cut to recurrent scene
Later in the movie, the field sizes of movie shots tend to decrease when
switching back to an already established settings (\texttt{vse\_old}).
% similarly for shots within a scene
When the spatial layout within a setting is already established, shots tend to
more often depict (faces of) persons talking to each others or objects more
relevant to the evolved plot (\texttt{vpe\_old}) \citep{brown2012cinematography,
mercado2011filmmakers}.
% neuroscientific rationale The neuroscientific rationale was that activity in
% the PPA is greater when participants view novel versus repeated scenes or
% view-points \citep{epstein1999parahippocampal, grill2006repetition}.  no cut
% condition: intro
In order to create a control condition, a sixth category (\texttt{no\_cut}) was
created by pseudo-randomly drawing movie frames from continuous movie shots that
lasted longer than \unit[20]{s}.
% no cuts: how
Events were drawn from movie shots in such a way that each event had a minimum
temporal distance of at least \unit[10]{s} to a movie cut and to another
\texttt{no\_cut} event.


% AV regressors
\begin{table*}[h!]
    \caption{Overview of annotated stimulus features of audio-visual
    movie.
    Respective event counts are given for the whole stimulus (\texttt{all} and
    the segments that were used for the eight sessions of fMRI scanning).
    %\texttt{fg\_av\_ger\_pd} (perceptual differences of consecutive frames),
    %\texttt{fg\_av\_ger\_ml} (mean luminance of a frame),
    %\texttt{fg\_av\_ger\_lr} (difference in mean luminance of left and right
    %half),
    %\texttt{fg\_av\_ger\_ud} (difference in mean luminance of upper and
    %lower half),
    %\texttt{fg\_av\_ger\_lrdiff} (left-right volume difference), and
    %\texttt{fg\_av\_ger\_rms} (root mean square volume) represent one event
    %for every movie frame (\unit[40]{ms}).
    % For description of the two event categories of the audio-description's
    % narrator (\texttt{se\_new} and \texttt{se\_old}) to build contrast of
    % negative control see Table \ref{tab:ao-events}.
    }
\label{tab:av-events}
\footnotesize
\begin{tabular}{lp{3.5cm}lllllllll} \toprule \textbf{label} & \textbf{description} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\
\midrule
vse\_new &  change of the camera position to a setting not depicted before & \aoVsenewAll & \aoVsenewI & \aoVsenewII & \aoVsenewIII & \aoVsenewIV & \aoVsenewV & \aoVsenewVI & \aoVsenewVII & \aoVsenewVIII
\tabularnewline vse\_old & change of the camera position to a recurring setting & \aoVseoldAll & \aoVseoldI & \aoVseoldII & \aoVseoldIII & \aoVseoldIV & \aoVseoldV & \aoVseoldVI & \aoVseoldVII & \aoVseoldVIII
\tabularnewline
vlo\_ch & change of the camera position to another locale within the same setting & \aoVlochAll & \aoVlochI & \aoVlochII & \aoVlochIII & \aoVlochIV & 0 & \aoVlochV & \aoVlochVI & \aoVlochVII
\tabularnewline
vpe\_new & change of the camera position within a locale not depicted before & \aoVpenewAll & \aoVpenewI & \aoVpenewII & \aoVpenewIII & \aoVpenewIV & \aoVpenewV & \aoVpenewVI & \aoVpenewVII & \aoVpenewVIII
\tabularnewline
% vpe_old has no events in 3. So the indices are shifted
vpe\_old & change of the camera position within a recurring locale &
\aoVpeoldAll & \aoVpeoldI & \aoVpeoldII & 0 & \aoVpeoldIII & \aoVpeoldIV &
\aoVpeoldV & \aoVpeoldVI & \aoVpeoldVII
\tabularnewline
vno\_cut & frames within a continuous movie shot & \avVnocutAll & \avVnocutI & \avVnocutII & 0 & \avVnocutIII & \avVnocutIV & \avVnocutV & \avVnocutVI & \avVnocutVII
\tabularnewline
% se\_new & control for AD narrator & \aoSenewAll & \aoSenewI & \aoSenewII & \aoSenewIII & \aoSenewIV & \aoSenewV & \aoSenewVI & \aoSenewVII & \aoSenewVIII
% \tabularnewline
% se\_old & control for AD narrator & \aoSeoldAll & \aoSeoldI & \aoSeoldII & \aoSeoldIII & \aoSeoldIV & \aoSeoldV & \aoSeoldVI & \aoSeoldVII & \aoSeoldVIII
% \tabularnewline
fg\_av\_ger\_lr & left-right luminance difference & \avFgavgerlrAll & \avFgavgerlrI & \avFgavgerlrII & \avFgavgerlrIII & \avFgavgerlrIV & \avFgavgerlrV & \avFgavgerlrVI & \avFgavgerlrVII & \avFgavgerlrVIII
\tabularnewline
fg\_av\_ger\_lrdiff & left-right volume difference & \avFgavgerlrdiffAll & \avFgavgerlrdiffI & \avFgavgerlrdiffII & \avFgavgerlrdiffIII & \avFgavgerlrdiffIV & \avFgavgerlrdiffV & \avFgavgerlrdiffVI & \avFgavgerlrdiffVII & \avFgavgerlrdiffVIII
\tabularnewline
fg\_av\_ger\_ml & mean luminance & \avFgavgermlAll & \avFgavgermlI & \avFgavgermlII & \avFgavgermlIII & \avFgavgermlIV & \avFgavgermlV & \avFgavgermlVI & \avFgavgermlVII & \avFgavgermlVIII
\tabularnewline
fg\_av\_ger\_pd & perceptual difference & \avFgavgerpdAll & \avFgavgerpdI & \avFgavgerpdII & \avFgavgerpdIII & \avFgavgerpdIV & \avFgavgerpdV & \avFgavgerpdVI & \avFgavgerpdVII & \avFgavgerpdVIII
\tabularnewline
fg\_av\_ger\_rms & root mean square volume & \avFgavgerrmsAll & \avFgavgerrmsI & \avFgavgerrmsII & \avFgavgerrmsIII & \avFgavgerrmsIV & \avFgavgerrmsV & \avFgavgerrmsVI & \avFgavgerrmsVII & \avFgavgerrmsVIII
\tabularnewline
fg\_av\_ger\_ud & upper-lower luminance difference & \avFgavgerudAll & \avFgavgerudI & \avFgavgerudII & \avFgavgerudIII & \avFgavgerudIV & \avFgavgerudV & \avFgavgerudVI & \avFgavgerudVII & \avFgavgerudVIII
\tabularnewline
\end{tabular}
\end{table*}


% AD annotation
For the analysis of the AD stimulus, we extended a publicly available annotation
of speech \citep{hausler2021studyforrest} by further annotating words spoken by
the audio-description's narrator.
% annotation procedure
Two persons performed a categorization of (concrete and countable) nouns that
the narrator uses to describe the movie's missing visual content based on a set
of rules.
% preliminary annotation
A preliminary annotation was performed by one person according to the rules.
% corrections
Minor corrections due to incorrectly applied rules were done by the author.
% reference to table with rules and examples
A complete overview of all 18 noun categories, the rule for a word to belong to
a category, and examples can be seen in Table \ref{tab:descr-nouns-rules}.
% why and how of categories 1
Some categories reflect the verbal counterpart of the stimulus categories that
were used in the visual localizer experiment (e.g. \texttt{body}, \texttt{face},
\texttt{head}, \texttt{object}, \texttt{setting\_new}, and
\texttt{setting\_rec}).
% why and how of categories 2
Other categories were created to semantically cluster remaining nouns into
categories that had no counterpart in the visual localizer experiment (e.g.
\texttt{bodypart}, \texttt{female}, \texttt{fname}, \texttt{furniture},
\texttt{geo}, \texttt{geo-room}, \texttt{male}, and \texttt{persons}).
% categories in detail
%Nouns were categorized by the verbal clue they provide about the
%cinematographic scene's environment (\texttt{geo}, \texttt{geo-room};
%\texttt{setting\_new}, \texttt{setting\_old}), its inherent persons (e.g.
%\texttt{female}, \texttt{male}, \texttt{persons}), a person's body or worn
%clothes (\texttt{face}, \texttt{head}, \texttt{body}, \texttt{bodypart}), and a
%scene's inherent objects (\texttt{object}, \texttt{furniture}).  problem with
%hierarchical categories
The categories \texttt{setting\_new} and \texttt{setting\_rec} comprise not just
words that describe a setting as a whole (e.g. ``[in] Greenbow'', ``[in a]
disco'', ``[the platoon wades through a] rice field''). They also comprise words
that could count as a member of another category in case the narrator uses
these words to indicate a switch from one setting to another (e.g. ``[a]
physician'').
% how it was handled
These nouns were flagged with both categories during the initial annotation
procedure. In context of the current analyses these word are considered to
belong exclusively to the higher-level category of changing a setting
(\texttt{se\_new} or \texttt{se\_old}).
% pooling of categories
Some noun categories that were semantically similar and offered only a small
amount of counts were pooled resulting in 11 final event categories (see Table
\ref{tab:ao-events}). These event categories were then used to model hemodynamic
responses.


% table for descriptive nouns: categories, rules, examples counts
\begin{table*}[h!]
    \caption{Categories and rules to categorize the nouns spoken by
        the audio-description's narrator.
        Examples are given in English.
        Some of these initial 18 noun categories were pooled resulting in 11
        event categories that served as basis to build the regressors of the
        GLM
        (cf. Table \ref{tab:ao-events}).
        % The category \texttt{++} also contains adverbial of time.
}
\label{tab:descr-nouns-rules}
\begin{tabular}{lll}
\toprule
\textbf{category} & \textbf{rule} & \textbf{examples} \\
\midrule
body & trunk of the body; overlaid clothes & back, hip, shoulder; jacket, dress, shirt
\tabularnewline
bodypart & limbs & arm, finger, leg, toe
\tabularnewline
face & face or parts of it & face, ear, nose, mouth
\tabularnewline
female & female person & nurse, mother, woman
\tabularnewline
females & female persons & women
\tabularnewline
fname & female name & Jenny
\tabularnewline
    furniture & movable furniture (insides \& outsides) & bench, bed, table,
    chair
\tabularnewline
geo & immobile landmarks & building, tree, street, alley, meadow, cornfield \tabularnewline
geo-room & rooms \& locales or geometry-defining elements & living room; wall, door, window, floor
\tabularnewline
head & non-face parts of the head; worn headgear & head, hair, ear, neck;
helmet
\tabularnewline
male & male person & man, father, soldier
\tabularnewline
males & male persons & boys, opponents
\tabularnewline
mname & male name & Bubba, Kennedy
\tabularnewline
object & countable entity with firm boundaries & telephone, car
\tabularnewline
objects & countable entities & wheels, plants
\tabularnewline
persons & concrete persons of unknown sex & hippies, patients
\tabularnewline
setting\_new & a setting occurring for the first time & on a ``bridge'', on an ``alley'', on ``campus''
\tabularnewline
setting\_rec & a recurring setting & at the ``bus stop'' \tabularnewline
% ++ & cue regarding time & in the ``evening'', it's ``daytime'', ``later'' \tabularnewline
\bottomrule
\end{tabular}
\end{table*}


% AD regressors
\begin{table*}[h!]
    \caption{Overview of annotated stimulus features of the audio-description.
    Respective event counts are given for the whole stimulus (\texttt{all} and
    the segments that were used for the eight sessions of fMRI scanning.
    Some of the annotation's original categories (female, females, fname; male,
    males, mname; face, head; object, objects;
    see Table\ref{tab:descr-nouns-rules}) were pooled
    into 11 new categories (\texttt{sex\_f}; \texttt{sex\_m}; \texttt{fahead},
    \texttt{object}).
    % For a description of the five control conditions for movie cuts see
    % Table \ref{tab:av-events}.
    }
\label{tab:ao-events} \footnotesize
\begin{tabular}{lp{3.5cm}lllllllll}
\toprule \textbf{label} & \textbf{description} & \textbf{all} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\
\midrule
body & trunk of the body; overlaid clothes & \aoBodyAll & \aoBodyI & \aoBodyII
& \aoBodyIII & \aoBodyIV & \aoBodyV & \aoBodyVI & \aoBodyVII & \aoBodyVIII
\tabularnewline
bpart & limbs and trousers & \aoBpartAll & \aoBpartI & \aoBpartII & \aoBpartIII & \aoBpartIV & \aoBpartV & \aoBpartVI & \aoBpartVII & \aoBpartVIII
\tabularnewline
fahead & face(parts) or head(parts) & \aoFaheadAll & \aoFaheadI & \aoFaheadII & \aoFaheadIII & \aoFaheadIV & \aoFaheadV & \aoFaheadVI & \aoFaheadVII & \aoFaheadVIII
\tabularnewline
furn & moveable furniture (insides \& outsides) & \aoFurnAll & \aoFurnI & \aoFurnII & \aoFurnIII & \aoFurnIV & \aoFurnV & \aoFurnVI & \aoFurnVII & \aoFurnVIII
\tabularnewline
geo & immobile landmarks & \aoGeoAll & \aoGeoI & \aoGeoII & \aoGeoIII & \aoGeoIV & \aoGeoV & \aoGeoVI & \aoGeoVII & \aoGeoVIII
\tabularnewline
groom & rooms \& locales or geometry-defining elements & \aoGroomAll & \aoGroomI & \aoGroomII & \aoGroomIII & \aoGroomIV & \aoGroomV & \aoGroomVI & \aoGroomVII & \aoGroomVIII
\tabularnewline
object & countable entities with firm boundaries & \aoObjAll & \aoObjI & \aoObjII & \aoObjIII & \aoObjIV & \aoObjV & \aoObjVI & \aoObjVII & \aoObjVIII
\tabularnewline
se\_new & a setting occurring for the first time & \aoSenewAll & \aoSenewI & \aoSenewII & \aoSenewIII & \aoSenewIV & \aoSenewV & \aoSenewVI & \aoSenewVII & \aoSenewVIII
\tabularnewline
se\_old & a recurring setting & \aoSeoldAll & \aoSeoldI & \aoSeoldII & \aoSeoldIII & \aoSeoldIV & \aoSeoldV & \aoSeoldVI & \aoSeoldVII & \aoSeoldVIII
\tabularnewline
sex\_f & female person(s), name & \aoSexfAll & \aoSexfI & \aoSexfII & \aoSexfIII & \aoSexfIV & \aoSexfV & \aoSexfVI & \aoSexfVII & \aoSexfVIII
\tabularnewline
sex\_m & male person(s), name & \aoSexmAll & \aoSexmI & \aoSexmII & \aoSexmIII & \aoSexmIV & \aoSexmV & \aoSexmVI & \aoSexmVII & \aoSexmVIII
\tabularnewline
% vlo_ch has no events in segment 5. So indices are shifted
%vse\_new & control for movie cut & \aoVsenewAll & \aoVsenewI & \aoVsenewII & \aoVsenewIII & \aoVsenewIV & \aoVsenewV & \aoVsenewVI & \aoVsenewVII & \aoVsenewVIII
%\tabularnewline
%vse\_old & control for movie cut & \aoVseoldAll & \aoVseoldI & \aoVseoldII & \aoVseoldIII & \aoVseoldIV & \aoVseoldV & \aoVseoldVI & \aoVseoldVII & \aoVseoldVIII
%\tabularnewline
%vlo\_ch & control for movie cut & \aoVlochAll & \aoVlochI & \aoVlochII & \aoVlochIII & \aoVlochIV & 0 & \aoVlochV & \aoVlochVI & \aoVlochVII
%\tabularnewline
%vpe\_new & control for movie cut & \aoVpenewAll & \aoVpenewI & \aoVpenewII & \aoVpenewIII & \aoVpenewIV & \aoVpenewV & \aoVpenewVI & \aoVpenewVII & \aoVpenewVIII
%\tabularnewline
% vpe_old has no events in 3. So the indices are shifted
%vpe\_old & control for movie cut & \aoVpeoldAll & \aoVpeoldI & \aoVpeoldII & 0 & \aoVpeoldIII & \aoVpeoldIV & \aoVpeoldV & \aoVpeoldVI & \aoVpeoldVII
% \tabularnewline
fg\_ad\_lrdiff & left-right volume difference & \aoFgadlrdiffAll & \aoFgadlrdiffI & \aoFgadlrdiffII & \aoFgadlrdiffIII & \aoFgadlrdiffIV &
\aoFgadlrdiffV & \aoFgadlrdiffVI & \aoFgadlrdiffVII & \aoFgadlrdiffVIII
\tabularnewline
fg\_ad\_rms & root mean square volume & \aoFgadrmsAll &
\aoFgadrmsI & \aoFgadrmsII & \aoFgadrmsIII & \aoFgadrmsIV & \aoFgadrmsV &
\aoFgadrmsVI & \aoFgadrmsVII & \aoFgadrmsVIII
\tabularnewline
\bottomrule
\end{tabular}
\end{table*}

% low-leve confounds: intro
Lastly, we algorithmically annotated the temporal structure of low-level
perceptual features to create nuisance regressors.
% visual shit
For the AV stimulus, we computed the mean luminance of a movie frame
(\unit[40]{ms}), the difference in mean luminance of each frame's left and right
half, the difference in mean luminance of the lower and upper half, and finally
the perceptual difference of consecutive frames.
% auditory shit
Finally for both audio tracks, we computed the left-right difference in volume
and root mean square energy averaged across the length of every movie frame
(\unit[40]{ms}).


\subsection{Hemodynamic Modeling}

% movie events
The events of the movie cut related categories and \texttt{no\_cut} events were
modeled as box car events of 200 ms duration.
%
Nouns were modeled from onset to offset of each word, low-level confounds from
onset to offset of the corresponding movie frame
% convolving
Events for all regressors of the AV and AO stimulus were convolved with a double
gamma hemodynamic response function (HRF).

% we checked correlations
Since we annotated events in fixed time courses, the modeled hemodynamic
time-series could be correlated leading to shared variance and thus low
detection power of subsequent analyses.
% correlations within stimuli and across stimuli
Hence, we tested for correlation of regressors across the eight segments of each
stimulus and also for correlations of regressors across both stimuli (s. Figure
\ref{fig:reg-corr})
% correlations within each stimulus
The computed Pearson correlation coefficients demonstrate no to minor
correlations of modeled hemodynamic time-series belonging to the same stimulus.
% (highest) correlations across stimuli
The highest correlations are apparent between auditory low-level confounds
across stimuli (\texttt{fg\_av\_ger\_rms} and \texttt{fg\_ad\_rms}, r=.7635;
\texttt{fg\_av\_ger\_lrdiff} and \texttt{fg\_ad\_lrdiff} and , r=.7749).
% no surprise
This was expected and served as a ``sanity check'' since the audio track of the
audio-description is the audio track of the movie but featuring the additional
narrator (s. Figure \ref{fig:reg-corr}).
% encouraged by that we build contrasts (statement)
As a result, we felt encouraged to create voxel-wise GLM $t$-contrasts similarly
to previous studies that used controlled stimuli.


\begin{figure*}[h!]
\centering
    \includegraphics[width=\linewidth]{figures/regressor-corr} \caption{Pearson
        correlation coefficients of modeled time series used as regressors in
        the GLM analysis of the
        audio-description (blue; see Table \ref{tab:ao-events} for a
        description) and audio-visual movie (red; see Table
        \ref{tab:av-events}).
        Values are rounded to the nearest tenth.
        The correlation between the two stimuli's
        root mean square volume and between their left-right difference in
        volume yielded the highest correlation values
        (\texttt{fg\_ad\_rms} and \texttt{fg\_av\_ger\_rms}, r=.7635;
        \texttt{fg\_ad\_lrdiff} and \texttt{fg\_av\_ger\_lrdiff}, r=.7749).
        \todo[inline]{checked it, all labels listed}
      }
\label{fig:reg-corr}
\end{figure*}


% AV design matrix
For the subsequent first level GLM analysis of the AV stimulus, the modeled
hemodynamic responses related to all movie cuts (including \texttt{no\_cut}) and
six low-level perceptual confounds were included as regressors in the design
matrix.
% AD regressors in AV AD design matrix
For the first level analysis of the AD stimulus, the modeled hemodynamic
responses related to all noun categories and the two low-level perceptual
confounds were included.
% AD regressors in AV
To create a contrasts of cross-modal control in the analysis of the AV stimulus,
we also implemented the regressors based on nouns used by the
audio-description's narrator to indicate a switch to another setting (categories
\texttt{se\_new} and \texttt{se\_old}).
% AV regressors in AV
To create contrasts of cross-modal negative control in the analysis of the AD
stimulus, we also implemented the movie cut-related regressors
(excluding \texttt{no\_cut}).
% both stimuli: null regressors
For both stimuli, a null regressor was chosen for a event category in a segment,
if that segment did not contain an event of the category (e.g. no event of
\texttt{vpe\_old} in segment 3; cf. Table \ref{tab:ao-events}).
% temporal derivatives
Temporal derivatives were included in the design matrix to compensate for
regional differences between modeled and actual HRF \citep{friston1998event}.
% motion parameters
Six motion parameters were also included.
% high-pass filtering
Finally, designs were filtered with the same high-pass filter (cutoff period of
\unit[150]{s}) as the BOLD time series.


\subsection{Statistical analysis}

% intro
We tested our modeled hemodynamic responses based on stimulus annotations by
conducting standard two-level general linear model (GLM) analyses to create
subject-specific results across the 8 segments for every subject and each
stimulus.
% level 3
Subsequent, third-level analyses averaged contrast estimates over subjects.

% similar to previous studies
On the first level, we created GLM contrasts based on annotated stimulus
features embedded in the in the audio-visual movie and its audio-description.
% intro
To test the robustness of this approach, we operationalized the perception of
spatial information compared to the perception of non-spatial information
differently in five $t$-contrasts for the AV stimulus (see Table
\ref{tab:av-contrasts}) and eight $t$-contrasts for the AD stimulus (see Table
\ref{tab:ao-contrasts}).
% reason: robustness
We assumed all contrasts could in principle correlate with increased hemodynamic
activity in the PPA but chose one contrast to be the ``primary contrast'' for
later detailed inspection and report.
% selection criteria for primary contrast.
The selection criterion for the primary contrast of each stimulus was a
subjectively good balance between a) how well the average of events within
categories represented spatial information and non-spatial information
respectively (cf. section \ref{rationale}), and b) the amount of available data.
% AV: primary contrast
In the primary contrast of the AV stimulus, we contrasted cuts to a setting that
was not depicted before (\texttt{vse\_new}) to cuts merely switching the camera
position within a setting that was already established earlier in the movie
(\texttt{vpe\_old}).
% why
We assumed that the category \texttt{vse\_new} on average comprised the most
movie frames depicting a landscape or the geometry of a setting, and the
category \texttt{vpe\_old} the most frames depicting persons, faces, or objects
[(cf.  rationale to categorize the cuts in section \ref{rationale})].
% AD: primary contrast
In the primary contrast of the AD stimulus, we contrasted buildings and
landmarks (\texttt{geo}), and rooms and geometry-defining objects
(\texttt{geo-room}) with not just nouns referring to a person's head or face
(\texttt{fahead}, N=83; e.g.  ``eyes'', ``face'', or ``head'') but also all
non-geometry related categories (\texttt{body}, \texttt{bodypart},
\texttt{fahead}, \texttt{object}, \texttt{sex\_f}, \texttt{sex\_m}) except
\texttt{furniture} to get more events per stimulus segment.\todo{ouff}
% why furniture was not used
The category ``furniture'' (\texttt{furn}) was not used as a regressor of
interest in any contrast because these nouns could be perceived as either a
geometry-defining scene element or as an isolated object.
% why se_new & se_old were not used in the primary contrasts
The categories of nouns indicating a switch to a setting that occurred for the
first time (\texttt{se\_new}) or a setting that recurred during the plot
(\texttt{se\_old}) were not included in the primary contrast because
% heterogeneous category
a) categories comprise nouns that could count as a member of another category
(e.g. ``[a] physician''; section \ref{rationale}), and
% richness of verbal description vs. picture
b) nouns that only vaguely describe a scene (e.g. ``[in] Greenbow'', ``[in a]
disco'', ''[black and white] film recordings'') [compared to whole, perceptually
richer pictures].
% and c) the narrator is often lacking behind a short dialogue or a change of
% the soundscape that might already indicate a change of settings.

% control contrasts
Finally, we created several $t$-contrasts as negative controls for both stimuli
(see Tables \ref{tab:av-contrasts} and \ref{tab:ao-contrasts}).
% AV: no cut > cut
For the AV stimulus, four contrasts were created contrasting the no-cut
regressor (\texttt{vno\_cut} to cut-related regressors \ref{tab:av-contrasts}).
% AV: narrator
One contrast (\texttt{vs\_new} > \texttt{vpe\_old}) was created by contrasting
nouns spoken by the narrator.
% AD stimulus
For the AD stimulus, we created five $t$-contrasts (see Table
\ref{tab:ao-contrasts}) to test if increased activation in the PPA was
correlated with moments of cuts.

% difference to Sengupta; Berman et al. (2010). Evaluating functional localizers
% (2010)
In the VIS study using the established approach of contrasting blocks of
pictures, a set of three contrasts (\textit{strict}, \textit{relaxed}, and
\textit{simple} was created contrast (cf. \citep{sengupta2016extension}).


\begin{table*}[h!]
\caption{Contrasts of parameter estimates for the analysis of the
    audio-visual movie.
    Contrast 1-5 aim to isolate the PPA.
    Contrast 6-9 serve as negative control.
    Contrast 10 serves as control for moments when the narrator indicates
    a switch of settings.}
\label{tab:av-contrasts}
\footnotesize
\begin{tabular}{lll}
\toprule
\textbf{nr.} &  \textbf{contrast} & \textbf{purpose} \\
\midrule
1 & vse\_new > vpe\_old & PPA \tabularnewline
2 & vse\_new, vpe\_new > vse\_old, vpe\_old & PPA \tabularnewline
3 & vse\_new > vse\_old & PPA \tabularnewline
4 & vse\_new > vse\_old, vpe\_old & PPA \tabularnewline
5 & vse\_new, vpe\_new > vpe\_old & PPA \tabularnewline
6 & vno\_cut > vse\_new & negative control \tabularnewline
7 & vno\_cut > vse\_old & negative control \tabularnewline
8 & vno\_cut > vse\_new, vse\_old & negative control \tabularnewline
9 & vno\_cut > vpe\_new, vpe\_old & negative control \tabularnewline
10 & se\_new > se\_old & control for (missing) narrator \tabularnewline
\end{tabular}
\end{table*}


\begin{table*}[h!]
\caption{Contrasts of parameter estimates for the analysis of the audio-only
    stimulus.
    Contrast 1-8 aim to isolate the PPA.
    \texttt{non-spatial categories} refers to the categories
    \texttt{body}, \texttt{bodypart}, \texttt{fahead},
    \texttt{object}, \texttt{sex\_f}, \texttt{sex\_m}.
    Contrasts 9-13 serve as negative control contrasts at the moments of movie
    cuts (see Table \ref{tab:av-contrasts}).}
\label{tab:ao-contrasts}
\footnotesize
\begin{tabular}{lll}
\toprule
\textbf{nr.} &  \textbf{contrast} & \textbf{purpose} \\
\midrule
1 & geo, groom > non-spatial categories & PPA \tabularnewline
2 & geo, groom, se\_new > non-spatial categories & PPA \tabularnewline
3 & groom, se\_new, se\_old > non-spatial  & PPA \tabularnewline
4 & geo > non-spatial categories & PPA \tabularnewline
5 & groom > non-spatial categories & PPA \tabularnewline
6 & se\_new > non-spatial categories & PPA \tabularnewline
7 & se\_new, se\_old > non-spatial categories & PPA \tabularnewline
8 & se\_new > se\_old > non-spatial categories & PPA \tabularnewline
9 & vse\_new > vpe\_old & control at moments of cuts \tabularnewline
10 & vse\_new, vpe\_new > vse\_old, vpe\_old & control at moments of cuts \tabularnewline
11 & vse\_new > vse\_old & control at moments of cuts \tabularnewline
12 & vse\_new > vse\_old, vpe\_old & control at moments of cuts \tabularnewline
13 & vse\_new, vpe\_new > vpe\_old & control at moments of cuts \tabularnewline
\end{tabular}
\end{table*}


% alignments single subjects (for Bland-Altman-Plots) 1st level
The GLM analysis that fitted each voxel's time course separately for each
subject and segment was performed in functional space preserving the orientation
of the EPI images.
% two ways of co-registration
Subject-specific BOLD T2* time series were anatomically co-registered in two
ways:
% subject template (for Bland-Altman-Plot of unthresholded maps)
% \href{"https://github.com/psychoinformatics-de/studyforrest-data-templatetransforms/blob/master/sub-01/bold3Tp2/brain.nii.gz"}{example})
a) via linear transformation to a subject-specific, study-specific T2* template
(cf. \citep{sengupta2016extension}), and
% group template (for group and individual brain slices)
% https://github.com/psychoinformatics-de/studyforrest-data-templatetransforms/blob/master/templates/grpbold3Tp2/brain.nii.gz"
b) via non-linear transformation to a study-specific T2* group template (cf.
\citep{hanke2014audiomovie}).
% MNI152
This group template was co-registered to the MNI 152 template with an affine
transformation (12 degrees of freedom) to facilitate visualization and
identification of cortical structures.

% second level model
The second level analyses which averaged contrast estimates over the eight
stimulus segments were carried out using a fixed effects model by forcing the
random effects variance to zero in FLAME (FMRIB's Local Analysis of Mixed
Effects; \citep{beckmann2003general, woolrich2004multilevel}.
% thresholding (Z>2.3 in subject-space; Z>3.4 in group space)
(Gaussianised T/F) statistic images were thresholded using clusters determined
by Z>3.4 and a cluster-corrected significance threshold of p=.05
\citep{worsley2001statistical}.

% third level model
The third level analysis which averaged contrast estimates over subjects was
carried out using FLAME stage 1 with automatic outlier detection
\citep{beckmann2003general, woolrich2004multilevel, woolrich2008robust}.
% thresholding
Here again, Z (Gaussianised T/F) statistic images were thresholded using
clusters determined by Z>3.4 and a (corrected) cluster significance threshold of
p=.05 \citep{worsley2001statistical}.
% brain region identification
Brain regions associated with observed clusters were determined with the Jülich
Histological Atlas \citep{eickhoff2005toolbox, eickhoff2007assignment} and the
Harvard-Oxford Cortical Atlas \citep{desikan2006automated} provided by FSL.
% PPA masks
Regions of interest (ROI) masks for individual PPAs and a PPA group mask of
individual PPA overlaps were created from data provided by
\citep{sengupta2016extension}.


\section{Results}

\todo[inline]{SE: Antworten innerhalb "klassisch definierter"
PPA für die verschiedenen regressoren bzw. kategorien derselben (zumindest aber
places vs faces) aus? -> Peristimulus plots}

% study goal
We investigated if spatial information embedded in two naturalistic stimuli
correlates with increased hemodynamic activity in the PPA.
% group level
On a group average level, we compare results gained from whole-brain GLM
analyses of the movie and the audio-description to results gained from a
traditional visual localizer \citep{sengupta2016extension}.
% individual level
On the level single subjects, we also assess the performance of the exclusively
auditory naturalistic stimulus as a substitute for a visual paradigm to localize
the PPA.
% NeuroVault
Unthresholded $z$-maps of all contrasts on a group level as well as individual
results of the primary $t$-contrasts co-registered to the group-template (MNI152
space) can found at
\href{https://neurovault.org/collections/KADGMGVZ/}{NeuroVault}.
% reference to supplemental material
Results and discussion of the additional contrasts (PPA and negative controls)
can be found in the supplemental material

% AV intro
First, we analyzed data from the movie offering a visual but ecologically more
valid stimulation than static pictures.
% AV primary contrast
The movie's primary $t$-contrast that compared cuts to a setting that was not
depicted before to cuts within a recurring setting (\texttt{vse\_new >
vpe\_old}) yielded three significant clusters (see Table
\ref{tab:res-av-group1}, Figure \ref{fig:group-slices}).
% PPA (others the clusters extend into).
One cluster spans across the midline and comprises parts of the intracalcarine
and cuneal cortex, the lingual gyrus and retrosplenial cortex, the occipital and
temporal fusiform gyrus, and the parahippocampal cortex (reported from posterior
to anterior) in both hemispheres.
% LOC
Two additional homologous clusters are located in the superior lateral occipital
cortex.

% AD intro
Second, we analyzed data from the audio-description offering exclusively
auditory stimulation.
% AD primary contrast
The primary $t$-contrast for the audio-description (\texttt{geo, groom} >
non-spatial noun categories) yielded six significant clusters (see Table
\ref{tab:res-ao-group1}, Figure \ref{fig:group-slices}).
% overlap with ROI
Two homologous clusters are located in the anterior part of the PPA group
overlap.
% in detail
Specifically, these clusters are located at the borders of the posterior
parahippocampal cortex, the occipital and temporal fusiform gyrus and lingual
gyrus.\todo{Havard-Oxford atlas: 3 different most prob. locations depen. on
voxel}
% precuneus
Two additional homologous clusters are apparent in the ventral precuneus
extending into the retrosplenial cortex.
% LOC
Finally, two homologous clusters are located in the superior lateral occipital
cortex.

% figure group results primary AD & AV contrasts
\begin{figure*}[h!] \centering
    \includegraphics[width=\linewidth]{figures/group-slices}
    \caption{Mixed-effects group-level (N=14) GLM results. Significant clusters
        (Z>3.4, p<.05 cluster-corrected) are overlaid on the MNI152 T1-weighted
        head template (gray).
        Light gray: The audio-description's field of view
        (cf. \citep{hanke2014audiomovie}).
        Black: outline of overlapping individual PPA ROIs
        \citep{sengupta2016extension}.
        The results of audio-description's primary $t$-contrast (blue) that
        compares geometry-related nouns spoken by the narrator to non-spatial
        nouns (\texttt{geo, groom} > all non-spatial
        categories)
        are overlaid over the movie's primary $t$-contrast (blue) that compares
        cuts to a setting depicted for the first time with cuts within a
        recurring setting
        (\texttt{vse\_new > vpe\_old}).
        }
    \label{fig:group-slices}
\end{figure*}


\begin{table*}[h!]
\caption{Significant clusters (z-threshold Z>3.4; p<.05 cluster-corrected)
    of the primary $t$-contrast for the audio-visual movie comparing cuts to a
    setting depicted for the first time with cuts within a recurring setting
    (\texttt{vse\_new > vpe\_old}).
    Clusters sorted by voxel size.
    The first brain structure given contains the voxel with the maximum Z-Value,
    followed by brain structures from posterior to anterior, and partially
    covered areas (l. = left; r. = right; c. = cortex; g. = gyrus).}
\label{tab:res-av-group1}
\begin{tabular}{rrrrrrrrrp{3cm}}
\toprule
& & & \multicolumn{3}{r}{max location (MNI)} & \multicolumn{3}{r}{center of gravity (MNI)} &
\\ \cmidrule{4-6} \cmidrule{7-9}
voxels & $p_{corr.}$ & Z-max & x & y & z  & x & y & z & structure \\
\midrule
3003 & 0 & 5.31 & 22.5 & -45.5 & -12 & 4.53 & -63.3 & -3.72 & r. lingual g.; r.
cuneal c., intracalcarine c., bilaterally occipital fusiform g., precuneus,temporal fusiform c., posterior parahippocampal c.  \\
154 & 0.000000656 & 4.46 & -35 & -83 & 28 & -32.8 & -86.2 & 21.4 & l. superior lateral occipital c. \\
121 & 0.00000769 & 4.65 & 25 & -80.5 & 25.5 & 23.7 & -83.8 & 25.4 & r. superior lateral occipital cortex \\
\bottomrule
\end{tabular}
\end{table*}


% table group results primary AD contrast
\begin{table*}[h!]
    \caption{Significant clusters (z-threshold Z>3.4; p<.05 cluster-corrected)
        of the primary $t$-contrast for the audio-description comparing
        geometry-related nouns to non geometry-related nouns spoken by the
        audio-description's narrator (\texttt{geo, groom > all non-geo}).
        Clusters sorted by voxel size.
    The first brain structure given contains the voxel with the maximum Z-Value,
followed by brain structures from posterior to anterior, and partially covered
areas (l. = left; r. = right; c. = cortex; g. = gyrus).}
    \label{tab:res-ao-group1}
\begin{tabular}{rrrrrrrrrp{3cm}}
\toprule
& & & \multicolumn{3}{r}{max location (MNI)} & \multicolumn{3}{r}{center of gravity (MNI)} &
\\ \cmidrule{4-6} \cmidrule{7-9}
voxels & $p_{corr.}$ & Z-max & x & y & z  & x & y & z & structure \\
\midrule
188 & 0.0000000596 & 4.48 & -17.5 & -65.5 & 25.5 & -14.7 & -59.1 & 15.2 & l. precuneus \\
164 & 0.000000238 & 4.47 & 17.5 & -58 & 23 & 15.6 & -55.6 & 16 & r. precuneus; \\
83 & 0.000128 & 4.48 & 27.5 & -43 & -17 & 27.2 & -41.1 & -14 & r. temporal (occipital) fusiform c.; posterior parahippocampal g. \\
73 & 0.000318 & 3.93 & -22.5 & -43 & -12 & -23.9 & -43.6 & -11.2 & l. lingual g.; temporal (occipital) fusiform g., posterior parahippocampal c. \\
63 & 0.000824 & 4.1 & 40 & -75.5 & 30.5 & 40.9 & -76.3 & 28.6 & r. superior lateral occipital c. \\
37 & 0.0129 & 4.24 & -37.5 & -78 & 33 & -38.4 & -79.5 & 28.9 & l. superior lateral occipital c. \\
\bottomrule
\end{tabular}
\end{table*}


% results in detail voxels of significant clusters in PPA ROI (and RSC
% liberally)
% sub-01 (m): PPA (l/r), AD (l/r), AV (-/r); RSC: AD (l/r), AV (-/-)
% sub-02 (m): PPA (l/r), AD (-/-), AV (l/-); RSC: AD (-/-), AV (-/-)
% sub-03 (f): PPA (l/r), AD (-/-), AV (-/r); RSC: AD (-/-), AV (-/-)
% sub-04 (f): PPA (-/r), AD (l/r), AV (-/r); RSC: AD (l/r), AV (-/-) !
% sub-05 (m): PPA (l/r), AD (-/-), AV (-/-); RSC: AD (-/-), AV (-/-)
% sub-06 (m): PPA (l/r), AD (l/r), AV (-/-); RSC: AD (l/-), AV (-/-)
% sub-09 (m): PPA (l/r), AD (l/-), AV (l/r); RSC: AD (l/r), AV (l/r)
% sub-14 (f): PPA (l/r), AD (l/r), AV (-/r); RSC: AD (l/r), AV (-/-)
% sub-15 (m): PPA (l/r), AD (l/r), AV (-/r); RSC: AD (l/r), AV (l/r)
% sub-16 (m): PPA (l/r), AD (l/r), AV (l/r); RSC: AD (l/r), AV (l/-)
% sub-17 (m): PPA (l/r), AD (l/r), AV (l/r); RSC: AD (l/r), AV (l/r)
% sub-18 (m): PPA (l/r), AD (l/r), AV (l/r); RSC: AD (l/r), AV (-/r)
% sub-19 (f): PPA (l/r), AD (l/r), AV (-/r); RSC: AD (l/r), AV (l/r)
% sub-20 (f): PPA (-/r), AD (-/-), AV (l/r); RSC: AD (-/-), AV (-/-)

% intro
Third, we investigated result from both naturalistic paradigms on the level of
individual subjects to ensure that the group results are not just a by-product
of the averaging process.
% AD is the real shit
Further, we hypothesized that an exclusively auditory stimulus could localize
the PPA in individual subjects and thus possibly substitute a classic visual
localizer experiment.
% Sengupta et al., 2016; unilateral in sub-04 and sub-20
The visual localizer yielded bilateral parahippocampal clusters in 12 of 14
subjects and an unilateral right clusters in two subjects (cf. Table 3 in
\citep{sengupta2016extension}).
% Sengupta: 1 of 3
Individual PPAs were assessed by visually inspecting thresholded $t$-maps
(Z>1.64, p<.05 cluster corrected) of three different $t$-contrasts, and
titrating\todo{??} the $t$-threshold in the range of [2, 3] in until we found an
isolated cluster (cf. Table 3 in that matched the expected anatomical location
based on literature \citep{epstein1998ppa}.

% one contrast to localize them all; "...and Z>3.4 for all"
Contrary to \citep{sengupta2016extension}, we here used the same contrast of
each naturalistic stimulus and the same threshold for all subjects.
% subject space -> NeuroVault
Results of the analyses that were performed in subject-space can be found in the
accompanying dataset (Z>2.3, p<.05 cluster-corrected).
% here report in group space
For better comparisons of subjects, we here report results from the analyses
performed in group space (Z>3.4, p<.05 cluster-corrected).
% ref to figure
Figure \ref{fig:subs-thresh-ppa} depicts thresholded $z$-maps of the primary AV
and AD $t$-contrast, and the outline of overlapped, individual PPAs
co-registered to the MNI152 template.
% one slice to show them all
Transversal slice of z=-11 was chosen as it depicts [at least some] voxels of
significant clusters in almost all subjects.

% AV
Results of the primary AV contrast yielded bilateral clusters in five subjects,
a unilateral right cluster in six subjects (of which one subjects yielded a
unilateral cluster in the visual localizer), and a unilateral left cluster in
one subject.
% difference to dedicated localizer
We find homologous clusters in sub-20, whereas the dedicated visual localizer
yielded only one cluster in the right hemisphere.

% report here in group
Results of the primary AD contrast yielded bilateral clusters in nine subjects
that are within or overlapping with the individual PPA.
% subj-04
In sub-04, two homologous clusters are apparent, whereas the dedicated localizer
(and AV stimulus) yielded only one cluster in the right hemisphere.
% sub-09
In sub-09 the analysis yielded one cluster in the left-hemispheric PPA.


\begin{figure*}[h!]
\centering
    \includegraphics[width=\linewidth]{figures/subs-thresh-ppa}
    \caption{Fixed-effects individual-level GLM results (Z>3.4, p<.05
        cluster-corrected).
        Individual brains are aligned via non-linear
        transformation to a study-specific T2* group template that is
        co-registered to the MNI152 template with an affine transformation (12
        degrees of freedom).
        The results of the audio-description's primary
        $t$-contrast (blue) that compares geometry related nouns to non-
        geometry related nouns spoken by the narrator
        (\texttt{geo, groom > all non-geo}) are overlaid over the movie's
        primary $t$-contrast (blue) that compares cuts to setting depicted for
        the first time with cuts within a recurring setting
        (\texttt{vse\_new > vpe\_old}).
        Black:
        outline of subject-specific PPA ROIs.
        Light gray: The
        audio-description's field of view (cf. \citep{hanke2014audiomovie}).
        To facilitate comparisons across subjects, we chose the same horizontal
        slice (x=-11) for all subjects as this slice depicts voxels of
        significant clusters in almost all subjects.
        The figure does not show voxels of the left cluster of the AV stimulus
        in sub-09 and sub-18, and voxels of the right cluster of the AV
        stimulus in sub-15.}
    \label{fig:subs-thresh-ppa}
\end{figure*}

% Bland-Altman-Plots
To better depict the agreement and difference between the results of the visual
localizer and the primary AD contrast, we created a Bland-Altman-Plot for every
subject (see Figure \ref{fig:bland-altman}).
% what it depicts
Each subplot visualizes the mean value and difference (localizer minus AD) of
two spatially corresponding voxels in the unthresholded $z$-maps.
% top KDE plot
A shift of the distribution to voxels with a mean above zero can be seen the
further we constrain voxels to the individual PPA (cf. KDE plot for the x-axes).
% right KDE plot
Values above the horizontal line depict voxels that show a higher $z$-value in
the dedicated localizer, values below the horizontal line depict voxels that
show a higher $z$-value in the AD stimulus.

\begin{figure*}[h!]
\centering
    \includegraphics[scale=0.27]{figures/subjs_bland-altman.png}
    \caption{Bland-Altman-Plots for individual subjects.
    The x-axes show the means of two spatially corresponding voxels in the
    unthresholded $z$-map of the audio-description's primary contrast and
    unthresholded $z$-map of the visual localizer (KDE plot on the top).
    The y-axes show the difference of two voxels (localizer minus
    audio-description; KDE plot on the right).
    The overlays depict voxels spatially constrained to the
    temporal and occipital cortex (gray; based on probabilistic Jülich
    Histological Atlas \citep{eickhoff2005toolbox, eickhoff2007assignment}),
    PPA overlap of all subjects (blue),
    and individual PPA(s) (red).}
    \label{fig:bland-altman}
\end{figure*}


\section{Discussion}

% Discussion: explains how results fill gap identified in intro

% typically done by recapitulating the results, discussing limitations, and then
% revealing how the central contribution may catalyze future
% progress

% provides caveats to the interpretation describes how the paper
% advances the field by providing new opportunities


% previous studies
Previous studies reported increased hemodynamic activity in the PPA when
participants were watching static pictures of landscape compared to pictures of
faces or objects (e.g. \citep{epstein1998ppa, epstein1999parahippocampal})
whereas one study using spoken sentences reported mixed results
\citep{aziz2008modulation}.
% current study: similar
In line with previous studies, we operationalized spatial perception via general
linear model (GLM) $t$-contrasts.
% current study: dissimilar
Contrary to previous studies, our current approach is not based on carefully
designed sets of stimuli but based on annotated stimulus features incidentally
occurring in two naturalistic stimuli.
% group AV
On a group level, whole brain-analysis results for the audio-visual movie show
significantly increased hemodynamic activity spatially overlapping with a
traditionally localized PPA but also extending into earlier visual cortices.
% group AD
Results for the audio-description also reveal significant activation in the PPA
but restricted to its anterior part.
% individual level
On an individual level, results of the audio-description show significant
bilateral clusters in the anterior PPA of nine subjects and a unilateral cluster
in one subjects.
% meaning: generalization to naturalistic stimuli
Results suggest that increased activation in the PPA during the perception of
static pictures generalize to the perception of spatial information embedded in
a movie and an exclusively auditory stimulus.
% meaning: aPPA vs. pPPA
Our results provide further evidence that the PPA can be divided into functional
subregions.
% narrative as substitute
An auditory narrative might substitute a visual paradigm to localize the PPAs
anterior part in visually impaired subjects.


% PPA: intro
First, we analyzed data from the movie offering ecologically more valid visual
stimulation.
%
An early study \citep{bartels2004mapping} that manually annotated the content of
movie frames (color, faces, language, and human bodies) found that
specialization of functional areas is preserved during movie watching.
%
Contrary to \citep{bartels2004mapping} who annotated the content of movie
frames, we categorized each frame after a cut independent of its specific
content  \todo{Bartels' clusters are actually pretty big too}
% exploited cinematographic tendencies
exploiting a cinematographic confound in the stimulus structure (cf. section
\ref{rationale}):
% establishing shots vs. e.g. over-the-shoulder shots
film directors tend to establish the geometry of locations earlier in the movie
and tend to later focus more on persons and objects relevant to the evolved plot
\citep{brown2012cinematography, mercado2011filmmakers}.
% hypo
Despite our ad hoc approach, we hypothesized that confounding variables would
average out, and our whole-brain analyses would lead to significant clusters in
the PPA.
% results
Group results of the AV stimulus' primary contrast yielded one cluster that
spans the group overlap of individual PPA ROIs from anterior to posterior.
% confound of higher perception
The cluster's extension into more posterior, early visual areas can be
attributed to the averaging process that did not control for confounding visual
features.
% solution
Thus to control confounding variables, future studies that aim to use a movie to
localize visual areas in individual subjects should extensively annotate the
content of frames (e.g.  using the open-source solution ``Pliers'' for feature
extraction from a visual naturalistic stimulus; \citep{mcnamara2017developing}).
% we took advantage of cinematography
We here took advantage of an idiosyncrasy of movie directing to shift from
depicting the spatial layout to to later depicting persons and objects.
% know your stimulus
Given that this shift is common in movies, investigators should be aware that
cinematographic tendencies are part of movie's confound structure that might,
depending on the research question, influence the results.
% conclusion
In summary, results from the visual localizer paradigm using blocks of pictures
generalize to an ad hoc approach to operationalize the perception of spatial
information at the moment of cuts in an audio-visual movie.

% intro
Second, we analyzed data from the audio-description offering exclusively
auditory stimulation.
% hypothesis
Encouraged by \citep{aziz2008modulation}, we hypothesized that spatial
information embedded in the AD stimulus would correlate with increased
hemodynamic activity in the PPA.
% diff to Aziz (2008)
\citep{aziz2008modulation} modeled events from on- to offset of sentences
(describing unknown and famous places and faces), and compared activity levels
that were averaged across voxels of ROIs (PPA and fusiform face area, FFA
\citep{kanwisher1997ffa}) defined by a localizer experiment.
% Aziz results
Study results revealed significantly decreased activity in only the left PPA
compared to activity in the FFA for sentences describing famous places compared
to famous faces.
% we: model & whole brain
Here we modeled events from on- to offset of single words and performed a
whole-brain analysis.
% our results
Group results of the audio-description's primary contrast yielded significantly
increased hemodynamic activity spatially restricted to the anterior part of the
PPA group overlap.
% concluding statement
Contrary to \citep{aziz2008modulation}, our group results suggest that auditory
spatial information compared to non-spatial information correlates with
bilaterally increased activation in the anterior part of the PPA.

% previous studies: no task
Usually studies that use small sets of experimentally controlled stimuli also
employ a task to keep subjects attentive to the stimuli.
% but: Epstein (1998)
Nevertheless, one early block-design study \citep{epstein1998ppa} compared
results from a paradigm that employed a perceptual judgment task of static
pictures to the same paradigm but without that task.
% results during no task
Hemodynamic activity was less but still significantly increased when
participants had no task to keep them alert and attentive to the stimuli.
% we have no task neither
Our paradigm is similar in that sense that our participants had no behavioral or
cognitive task (e.g. forming a mental image of the stimuli; cf.
\citep{ocraven2000mental})  but just had to ``enjoy the audio-description''.
% but still: we are different
Our paradigm still differs from \citep{epstein1998ppa} because the modeled
stimulus features were incidentally embedded in a continuous stream of auditory
information preventing participants from making assumptions about the
investigated perceptual process.
% concluding statement: kinda automatic process
Hence, current results also suggest that verbal spatial information is processed
in the anterior PPA casually and does not [necessarily] rely on [deliberately]
paying attention to verbal spatial information.


% AD shortcomings

% optimal stimulus type in vision
In the visual domain, pictures of landscapes and not pictures of landmarks or
buildings are considered to be the ``optimal'' stimulus type
\citep{epstein2008parahippocampal}.
% we did not choose se\_new and se\_old
In the AD's primary contrast, we did not include the categories that contained
switches from one setting to another (\texttt{se\_new} and \texttt{se\_old})
which one might assume to contain the auditory equivalent to pictures of
landscapes.
% why
The reason was that the categories \texttt{se\_new} and \texttt{se\_old} were
heterogeneous: they rarely contained holistic (but also vague) descriptions of
landscapes (e.g.  ``[Forrest is running through the] jungle'') but mostly
landmarks or buildings, and also non-spatial hints (e.g. ``[Jenny as a]
teenager``).
% visual system => gist in milliseconds
Humans can identify the gist of a rich visual scene within the duration of a
single fixation \citep{henderson2003human}.
%
Hence, further studies might investigate if vague verbal descriptions of
landscapes lead to a different hemodynamic activity level than descriptions of
more concrete parts of a scene (e.g.``[a] beacon'', [a] ``farmhouse'').


% AD annotation > AV annotation
Given that the annotation of nouns offered a more precise way to operationalize
the perception of spatial information than the annotation of cuts and locations,
we also hypothesized that analyzing the data from the audio-description could
localize the PPA in individual persons.
% results of dedicated localizer
The visual localizer \citep{sengupta2016extension} revealed bilateral ROIs in 12
of 14 subjects and a unilateral right ROI in two subjects (sub-04, sub-20).
%
Whereas \citep{sengupta2016extension} chose the subjectively ``best fitting''
$t$-threshold in $t$-map from one of three contrasts by visual judgment, we used
the same contrast and threshold (Z>3.4, p<.05 cluster-corrected) for all
subjects.
% in the current study
The audio-description yielded significant bilateral clusters in 9 of 14 subjects
(of which sub-04 shows only a right-lateralized PPA ROI), and a unilateral
significant cluster in one subject.
% similar: anterior part
Similarly to the group average results, results on an individual level also
revealed that clusters are spatially restricted to the anterior part of
individual PPAs.
% conclusion
Thus, the cluster location and size found on the group level is not just a
by-product of the averaging process but a reliable pattern across results of
individual study participants.
% concluding statement
Further, our exploratory analysis suggests that a naturalistic auditory stimulus
can [in principle] be applied to localize (the anterior part) of a higher-level
visual area in the majority of subjects.
% one threshold (and contrast) to rule them all
Nevertheless, further studies that aim for individual diagnostics / ROI
localization should inspect more than one contrast, and use an individual
threshold or a sphere around the local maximum \citep{poldrack2007region} in the
parahippocampal region.

\todo[inline]{discussion of Bland-Altman-Plots?; dunno if this is meaningful:
z-scores in the anterior part of PPA are higher in AD contrasts than in contrast
of localizer}

% question
The fact that clusters from the auditory stimulus are spatially restricted to
the anterior part of clusters from the visual paradigms raises the question if
the revealed correlation patterns can be attributed to different features
inherent in the visual compared to the verbal stimuli.
% visual scenes: probably submodules
In the domain of visual scene perception, previous studies provide evidence that
the PPA can be divided into functionally subregions that might process different
stimulus features.
% posterior: functionality
The posterior PPA (pPPA) is functionally more responsive than the anterior PPA
(aPPA) to low-level features of scenes or (abstract) objects
\citep{baldassano2013differential, nasr2014thinking,
rajimehr2011parahippocampal}.
% anterior cIPL is defined using the Eickhoff–Zilles PGp probabilistic
% cytoarchitectonic map
Contrary, the aPPA is functionally more responsive than the pPPA to high-level
features of scenes (e.g. real-word size \citep{park2015parametric}; a scene's
abstract identity/category \citep{marchette2015outside, watson2016patterns}) and
objects (e.g. spatial contextual associations \citep{aminoff2007parahippocampal,
aminoff2013role}).
% connectivity
Moreover, pPPA and aPPA show differences in connectivity profiles.
% posterior
The pPPA is more strongly functionally connected to the occipital visual cortex
than the aPPA \citep{baldassano2013differential, baldassano2016two}.
% including lateral occipital cortex (LOC) and transverse occipital sulcus (TOS)
% anterior
Contrary, the aPPA is more strongly functionally connected to portions of the
default mode network[, including caudal inferior parietal lobe (cIPL), the
restrosplenial complex (RSC), medial PFC and the lateral surface of the anterior
temporal lobe] \citep{baldassano2013differential, baldassano2016two}.
% conclusion: subregions
According to a hypothesis by \citep{baldassano2013differential} the PPA consists
of subregions that process different aspects of a visual scene and cooperate to
build a complete scene representation.
% Their distinct connectivity properties do suggest that each may be involved in
% specific aspects of visual and cognitive processing involved in the
% overarching goal of scene understanding \citep{baldassano2013differential}.
% The fact that anterior PPA had a lower sensitivity to our abstract object
% stimuli does not necessarily imply that this region does not use object
% information \citep{baldassano2013differential}. Previous work has shown that
% PPA responds to objects that have spatial associations [Aminoff et al. 2007],
% are space-defining [Mullally and Maguire 2011], and are
% navigationally-relevant [Janzen and Van Turennout 2004]. These types of
% responses require spatial memory and cannot be based purely on visual features
% like object shape. \citep{baldassano2013differential}.  pPPA
Similarly, our results suggest that the pPPA is more concerned with visual
aspects immanent in pictures or movie shots of landscapes.
% aPPA
The aPPA might be more concerned with non-visual aspects of spatial information
(e.g. spatial contextual information \citep{aminoff2013role,
aminoff2015associative, baumann2016functional}) as immanent in both visual and
verbal stimuli.


% RSC + LOC
Apart from the PPA, we find significantly increased activity in the dorsal
precuneus and posterior cingulate region (e.g. retrosplenial complex; RSC) and
lateral occipital cortex (LOC; more lateral in the AV stimulus, more medial in
the AD stimulus) across contrasts of both naturalistic stimuli.
% RSC intro
Like the PPA, the RSC and LOC repeatedly showed increased hemodynamic activity
in studies investigating visual spatial perception or navigation (see
\citep{chrastil2018heterogeneity, bettencourt2013role} for reviews).
% not random shit
Thus, our approach to operationalize spatial perception based on stimulus
annotations did not lead to significant clusters scattered across the brain but
restricted to a brain network that is assumed/known to be involved in (visual)
spatial perception and cognition.
%
This suggest that model-driven methods based on stimulus annotations are
suitable to reveal spatially concise functional areas and networks.
%
Nevertheless, ``cleanliness''/``neatness``  of results (i.e. the signal-cluster
to noise-cluster ration)\todo{if you know what I mean} depends on how many
events correlating with an assumed perceptual process the stimulus provides
and to the extent to which a naturalistic stimulus' multi-dimensionality is
annotated and statistically controlled.


\section{conclusion}

\todo[inline]{scientific data has no conclusion -> last paragraph}

% natural stimulation
Natural stimuli like movies \citep{eickhoff2020towards,
hasson2008neurocinematics, sonkusare2019naturalistic} or narratives
\citep{hamilton2018revolution, honey2012not, lerner2011topographic,
silbert2014coupled, wilson2008beyond} offer an easy to implement, (continuous,)
complex, immersive, task-free paradigm that more closely resembles our natural
dynamic environment than traditional experimental designs.

\begin{itemize}
\item We reuse public data for independent research question
\item GLM based on annotations to operationalize ``spatial perception''
\item Our results add evidence that model-driven analyses based in annotations
can be run on data from naturalistic stimuli to ``localize'' brain activity
correlating with specific perceptual processes.
\item ``localization performance'' relies on how well the model captures
different aspects of the stimuli's feature space.
\item PPA is functionally heterogeneous region
\item a complex but naturally engaging auditory stimulus like an
audiobook might in principle be used as a non-visual localizer for a variety of
brain functions in subjects who are not willing or able to follow task
instructions during brain scanning [would state that explicitly in the summary
at the end].
\end{itemize}

this study shows that already existing, publicly
available data can be re-used for independent research questions that provide
further evidence for existing theories/hypotheses and advance the field by
generating new findings \& hypothesis.


\subsection*{Code availability}

\todo[inline]{provide supporting source code; explain how/where other may
access data underlying the analysis}

\todo[inline]{if using custom code for dataset generation/processing: indicate
how code can be accessed (including restrictions to access)}

\todo[inline]{include infos on versions of used software}

\todo[inline]{any specific variables or parameters used to generate, test, or process the current dataset?}


\section*{Acknowledgements}

\todo[inline]{everything correct?}
\todo[inline]{Grant or contribution numbers may be acknowledged}
%
COH designed and performed the analyses, and wrote the manuscript.
%
MH provided critical feedback on the procedure and edited the manuscript.
%
SE provided critical feedback.
%
We are grateful to \href{www.florianschurz.de}{Florian Schurz} who initiated the
annotation of nouns and created its preliminary version.%


\section*{Competing financial interests}
The authors declare no competing financial interests.


\section*{Figures Legends}

\todo{Figures \& Tables have their own section, the editor puts them where he
wants them?}

\emph{We discourage the inclusion of figures in the
Supplementary Information \textendash{} all key figures should be included here
in the main Figure section.}

\emph{Figure legend must total no more
than 350 words, and may contain literature references.}


\section*{Tables}

\emph{tables provide summary information but should not be used to present
primary data (i.e. measurements).}


{\small\bibliographystyle{unsrtnat}
\bibliography{references}}

%\begin{thebibliography}{1}
%\expandafter\ifx\csname url\endcsname\relax
%  \def\url#1{\texttt{#1}}\fi
%\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
%\providecommand{\bibinfo}[2]{#2}
%\providecommand{\eprint}[2][]{\url{#2}}
%
%\bibitem{cite1}
%\bibinfo{author}{Califano, A.}, \bibinfo{author}{Butte, A.~J.},
%  \bibinfo{author}{Friend, S.}, \bibinfo{author}{Ideker, T.} \&
%  \bibinfo{author}{Schadt, E.}
%\newblock \bibinfo{title}{{Leveraging models of cell regulation and GWAS data
%  in integrative network-based association studies}}.
%\newblock \emph{\bibinfo{journal}{Nature Genetics}}
%  \textbf{\bibinfo{volume}{44}}, \bibinfo{pages}{841--847}
%  (\bibinfo{year}{2012}).
%
%\bibitem{cite2}
%\bibinfo{author}{Wang, R.} \emph{et~al.}
%\newblock \bibinfo{title}{{PRIDE Inspector: a tool to visualize and validate MS
%  proteomics data.}}
%\newblock \emph{\bibinfo{journal}{Nature Biotechnology}}
%  \textbf{\bibinfo{volume}{30}}, \bibinfo{pages}{135--137}
%  (\bibinfo{year}{2012}).
%\end{thebibliography}

\section{Data Citations}

\todo[inline]{clean the PPA dataset; upload as zip to zalando again?}

Bibliographic information for the data records described in the manuscript.

1. Lastname1, Initial1., Lastname2, Initial2., ...\& LastnameN, InitialN. \emph{Repository name} Dataset accession number or DOI (YYYY).

\appendix

\section{Supplementary Materials}

\subsection{Results}

\subsubsection{Robustness of group results across contrasts}

\todo[inline]{SE: use different colormap for overlap of contrasts' clusters}

% intro
In order to test the robustness of our approach, we created overall five
$t$-contrasts for the AV stimulus (see Table \ref{tab:av-contrasts}), and
overall eight $t$-contrast for the AD stimulus (see Table
\ref{tab:av-contrasts}) by varying the contrasted categories (and thus the
amount of available data), and how well the annotated events within categories
on average matched a stimulus type that we assumed to correlate with spatial
perception.
% NeuroVault
Unthresholded z -maps of all contrasts on a group level as well as individual
results of the primary t-contrasts co-registered to the group-template (MNI152
space) can found at NeuroVault
\href{https://neurovault.org/collections/KADGMGVZ/}{NeuroVault}.

% AV PPA contrasts
% 1 PPA (l/r); RSC (l/r), LOC (l/r), VisC (l/r),
% intracalcarine, cuneal, ling.c
% 2 PPA (l/r); RSC (-/-), LOC (l/r), VisC (-/-)
% 3 PPA (l/r); RSC (-/-), LOC (-/-), VisC (-/r), occ. fusisf. g.
% 4 PPA (l/r); RSC (l/r), LOC (l/r), VisC (-/-), lingual g., occ. fusif. g.
% 5 PPA (l/r); RSC (l/r), LOC (l/r), VisC (-/-), occ. fusif. g.

% AV results: PPA; biggest overlap in posterior part of PPA group overlap  =
% temporal occipital fusiform cortex
All five AV contrasts yielded significant bilateral clusters that
overlap with the PPA group overlap (see Figure \ref{fig:stability-slices}).
% AV: RSC & LOC
Reliably across contrasts of the AV stimulus, we find bilaterally
significant clusters also in the ventral precuneal cortex and posterior
cingulate gyrus (i.e. restrosplenial complex; contrasts 1, 4, 5), and lateral
occipital cortex (contrasts 1, 2, 4, 5).

% AD PPA contrasts
% 1 PPA (l/r); RSC (l/r), LOC (l/r)
% 2 PPA (l/r); RSC (l/r), LOC (l/r), r. sup.temp.C., r.fr.pole; putamen; etc
% 3 PPA (l/r); RSC (l/r), LOC (l/r),l&r sup.temp.C., anterior cing., paracing.
% 4 PPA (l/r); RSC (l/r), LOC (l/r)
% 5 PPA (l/r); RSC (l/r), LOC (-/-)
% 6 PPA (l/r); RSC (l/r), LOC (l/-), l&r sup.temp.C.; medial pref. c., precun
% 7 PPA (-/-); RSC (l/r), LOC (l/-), l&r sup.temp.C.; left frontal pole
% 8 PPA (-/-); RSC (-/-), LOC (-/-)

% AD: results
In results of the AD stimulus, all contrasts except contrast 7
(\texttt{se\_new}, \texttt{se\_old} > non-spatial categories) and contrast 8
(\texttt{se\_new} > non-spatial categories) yielded significant bilateral
clusters in anterior regions of the group PPA overlap (see Figure
\ref{fig:stability-slices}).
% AD: RSC & LOC
Reliably across contrast of the AD stimulus, we find bilaterally significant
clusters also in the ventral precuneus (all except contrasts 8), lateral
occipital cortex (bilateral in contrasts 1 to 4; unilateral in contrasts 6 and
7), and superior temporal cortices (bilateral in contrasts 3, 6, 7; unilateral
right in contrast 2).
% non-systematic
Lastly, some contrasts of the AD stimulus yielded significant clusters in
regions that were not statistically significant in three or more contrasts.
%
Contrast 2 yielded clusters in the anterior cingulate gyrus (bilateral), right
frontal pole, right frontal medial cortex, and right putamen.
%
Contrast 3 shows clusters in the anterior cingulate gyrus (bilateral), left
frontal pole, and left insular.
%
Contrast 7 shows clusters in the left frontal pole and left frontal operculum
[border to triangularis], left insular.
%
Contrast 6 shows one additional cluster in the right medial frontal cortex.


\begin{figure*}[h!]
\centering
    \includegraphics[width=\linewidth]{figures/stability-slices}
    \caption{Overlap of significant clusters (Z>3.4; p<.05, cluster corrected)
        The audio-description's contrasts 1-8 (blue; \ref{tab:ao-contrasts})
        are overlaid over the audio-visual movie's contrasts 1-5 (red;
        \ref{tab:av-contrasts}).
        Cluster are overlaid on top of the MNI152 T1-weighted head template
        (gray).
        Black: outline of overlapping individual PPA ROIs.
        Light gray: The audio-description's field-of-view (cf.
        \citep{hanke2014audiomovie}).
        The figure shows that some contrasts yielded significant clusters
        also in the lateral temporal and prefrontal cortex.
        }
    \label{fig:stability-slices}
\end{figure*}


\subsubsection{control contrasts}

% intro
For the purpose of negative control, we implemented five contrasts for every
stimulus.

% ---------- AV control contrasts ----------
% 6 nothing
% 7 nothing
% 8 nothing
% 9 nothing
%10 se_new > se_old (nouns but in AV stimulus):
% LOC (l/r) right PPA, bilateral sup. lat. occ. c., sup. parietal lobe (right)

% ---------- AD control contrasts ----------
% 9 PPA (-/-); RSC (-/r), LOC (-/-), left pars triangularis
%10 PPA (-/-); RSC (-/-), LOC (-/-)
%11 PPA (-/-); RSC (-/-), LOC (-/-),
%12 PPA (-/-); RSC (-/-), LOC (-/-), right posterior hippocampus
%13 PPA (-/-); RSC (-/-), LOC (-/-)

% AV: no_cut > x
In the analysis of the AV data, none of the four contrasts that compared the
\texttt{no\_cut} category to a movie cut category (see Table
\ref{tab:av-contrasts}) yielded significant clusters.
% AV using nouns
The contrast that used the narrator's nouns but in the AV stimulus
(\texttt{se\_new} > \texttt{se\_old}) yielded a significant cluster in the right
PPA and bilateral clusters in the superior lateral occipital cortices (the right
hemispheric cluster extending into the superior parietal cortex).\todo{cuts
correlate with the nouns}

% AD stimulus
In the analysis of the AD data, we created control contrasts based on events of
the annotated movie cuts (cf. Table \ref{tab:ao-contrasts})
% contrast 9
Contrast 9 (vse\_new > pe\_old) revealed one significant cluster in the left
inferior prefrontal cortex (pars triangularis) and right ventral
precuneus/posterior cingulate gyrus.
% contrast 12
Contrast 12 (\texttt{vse\_new} > \texttt{vse\_old}, \texttt{vpe\_old}) revealed
one cluster in the right posterior hippocampus.\todo{odd imo}


\subsection{Discussion}

\subsubsection{congruencies (PPA, RSC, LOC, others)}

\begin{comment}
    the mother of total confusion: Aminoff shifts the PPA along the
    anterior-poster axis depending on publication;
    in Aminoff (2007, 2013):
    anterior PPA = spatial associations,
    region anterior to (!) PPA = non-spatial associations;
    in Aminoff (2015):
    posterior PPA = spatial associations,
    anterior PPA = non-spatial associations;
    hence: complete bullshit;
    ignore Aminoff (2015) due to various reasons
\end{comment}


\todo[inline]{SE: wie unterscheiden sich die Kontraste?}
\todo[inline]{Wo sind welche Kontraste (z.B. im Ergebnis) von anderen abgewichen?}

% PPA AV
Regarding contrasts of the AV stimulus (see Table \ref{tab:av-contrasts}), all
five AV contrasts show significant bilateral clusters in the PPA but also
extending into more posterior brain regions.
% PPA AD
Regarding contrasts of the AD stimulus (see Table \ref{tab:ao-contrasts}), six
of overall eight contrasts show significant bilateral clusters in the anterior
part of the group PPA overlap.
% results indicate robustness
Thus, the results of the additional contrasts indicate that our findings are
robust and do not depend on the design of one specific contrasts.
% but
Nevertheless, results are sensitive to the contrasted categories and the amount
of available data.
% example
For example, contrast 8 of the AD stimulus (\texttt{se\_new} > \texttt{se\_old})
that used the most heterogeneous categories comprising the least amount of
events yielded neither a significant cluster in the right-hemispheric nor
left-hemispheric PPA.
% concluding statement
Hence, investigators that use model-driven analyses have to consider how many
events a naturalistic stimulus may provide and how homogeneous the events to be
averaged might be.



% intro
Apart from the PPA, we find significantly increased activity in the dorsal
precuneus and posterior cingulate region (e.g. retrosplenial cortex; RSC) and
lateral occipital cortex (LOC) across contrasts of both naturalistic stimuli.
% RSC intro
Like the PPA, the RSC (AV stimulus: significant clusters in 3 of 5 contrasts; AD
stimulus: 7 of 8 contrasts) and LOC (AV stimulus: 4 of 5 contrasts; AD stimulus:
unilateral in 2, bilateral in 4 of 8 contrasts) are known to be scene-selective
regions (see \citep{chrastil2018heterogeneity, bettencourt2013role} for
reviews).\todo{same part as in the main text but with number of contrasts}

% some backup text for RSC & LOC
\begin{comment}
% RSC
RSC is located in the retrosplenial cortex, and posterior cingulate region (BA
23 and 31) [51–56], near to the point where the calcarine sulcus joins the
parietal-occipital sulcus \citep{epstein2008parahippocampal}.
%
RSC location functionally defined. In context of scene perception, the RSC is
not necessarily spatially congruent with the anatomically defined retrosplenial
cortex [26] (BA 29 and 30) \citep{epstein2008parahippocampal} but functionally
defined as the posterior medial region that exhibits increased hemodynamic
activity to visual scenes and during mental imagination trough familiar
environments [8] \citep{epstein2008parahippocampal}.

\begin{itemize}
    \item \citep{chrastil2018heterogeneity}
    \item \citep{vann2009what}
    \item \citep{silson2019posterior}
    \item \citep{baldassano2016two}:
    \item RSC appears to be most directly involved in orienting the viewer to
    the structure of the environment (both within and beyond the borders of the
presented image) for the purpose of navigational planning; it encodes both
absolute location and facing direction [Vass and Epstein, 2013; Epstein and
Vass, 2014; Marchette et al., 2014], integrates across views presented in a
panoramic sequence [Park and Chun, 2009], and shows strong familiarity effects
[Epstein et al., 2007a,b].
\end{itemize}

% LOC
\begin{itemize}
\item Bettencourt (2013). The Role of Transverse Occipital Sulcus in Scene
    Perception
\item Dilks, Kanwisher (2013). The Occipital Place Area Is Causally and
    Selectively Involved in Scene Perception
\item Nasr (2011). Scene-selective cortical regions in human and nonhuman
    primates
\item Dilks (2011). Mirror-image sensitivity and invariance in object \& scene
    processing
\item MacEvoy and Epstein (2007). Position selectivity in scene- and
    object-responsive
\item Grill-Spector (2003). The neural basis of object perception
\item Hasson (2003). Large-scale mirror-symmetry organization
\item Nakamura (2000). Functional delineation of the human occipito-temporal
    areas
\item \citep{baldassano2016two} regarding functional difference pPPA vs. OPA:
    The functional distinction is unclear.
    Previous work has speculated about the purpose of the apparent ventral and
    dorsal ``duplication'' of regions sensitive to large landmarks, proposing
    that it may be related to different output goals (e.g., action planning in
    OPA, object recognition in pPPA)[Konkle and Caramazza, 2013], or to
    different input connections (e.g., lower visual field processing in OPA,
    upper visual field processing in pPPA)[Kravitz et al., 2013; Silson et al.,
    2015].
    OPA and pPPA may also use information from different visual
    eccentricities: OPA processing less peripheral, relatively high-resolution
    environmental features. pPPA processing more peripheral, large-scale
    geometry, and context [Baldassano et al., 2016a]
\end{itemize}

\end{comment}


% ``confounding'' clusters
Despite performing a whole brain analysis, we do not find many [random] clusters
in single contrasts or even systematically across contrasts that hamper the
interpretation of results.
% AV: null results regarding attention and eye movements
For example in the AV results, we do not find significant clusters that could be
attributed to cognitive processes like attention or eye movements.
% AD: auditory cortices
Nevertheless, contrasts of the AD stimulus that compare (among others) verbal
hints of the change of a setting (\texttt{se\_new} or \texttt{se\_old}) to all
non-spatial categories (cf. contrasts 2, 3, 6, 7) show significant clusters in
(primary and secondary) auditory cortices.
% averaging vs. nuisance regressors
This suggests that variance correlating with lower level auditory processes was
not averaged out across trials and nuisance regressors did not capture enough
variance.
% possible reason
Significant clusters in auditory cortices could be correlating with a possible
change of the soundscape when the narrator of the audio-description (or a cut in
the movie) switches to a another setting.
% concluding statement
Thus, investigators that use model-driven methods to investigate brain functions
using naturalistic stimuli should (extensively) annotate the stimulus material
and test for correlations among variables.


\subsection{negative controls and cross-modal controls}

\todo[inline]{why did I build contrasts of the no\_cut condition compared
to the movie cuts categories????}

\todo[inline]{discussion \& concluding statement}

The four control contrasts of the AV stimulus that compared the
\texttt{no\_cuts} to categories of movie cuts all lead to null results.

% AD anno in AV data
The AV contrast using nouns (\texttt{se\_new} > \texttt{se\_old}): PPA
(unilateral), LOC (bilateral); These noun categories show highest correlation
among nouns with their cut counterpart \texttt{se\_new} (nouns) is r$\approx$0.3
correlated with \texttt{vse\_new} (cuts); \texttt{se\_old} (nouns) is
r$\approx$0.4 correlated with \texttt){vse\_old}.

% AV anno in AV data
The the 5 AV PPA contrasts but with the AV data using cuts. All null results
except:
% contrast 9
vse\_new > pe\_old (conrast 9): left inferior prefrontal cortex (pars
triangularis) and right ventral precuneus/posterior cingulate gyrus.
% contrast 12
vse\_new > vse\_old, vpe\_old (contrast 12): one cluster in the right posterior
hippocampus.

\end{document}
\documentclass[english]{article}
